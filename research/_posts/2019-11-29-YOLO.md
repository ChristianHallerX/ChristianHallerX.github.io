---
title: Neural Networks for object detection and classification
image: /assets/img/research/YOLOcoverpng.jpg
description: >
  Identify objects in your images with computer vision algorithm YOLO.
---

You only look once (YOLO, empahsis on **once**) is an object detection system using Convolutional Neural Networks (CNN) targeted for real-time processing of camera feeds of all sorts. YOLO is faster than previous algorithm since it does two steps in one. The algorithm divides the image into tiles (e.g. 13x13) and runs the inference for object bounding boxes *and* object classification on all image tiles simultaneously through the CNN. For example, self-driving cars heavily rely on reliable and fast algorithms, since they need to identify other cars on the street with a camera mounted in the grille.

YOLOv2 can be run repeatedly over the input of a camera (30 frames/s) but can make inferences at a speed of 40 times/s! A total of 80 classes are detected in YOLOv2. Only recently YOLO9000 was trained using transfer learning from ImageNet to detect >9000 classes!


**Prediction on stock photos:**
<br><img src="/assets/img/research/3hyxd5.gif" alt="MyYOLOgif" style="width:720px">

Source: Photos from <a href="https://unsplash.com/" target="_blank">https://unsplash.com/</a>, with own inferences.

## How it works 

### 1. Intuition

The input image is divided into nH x nW grid (for example 13×13 in the architectureal diagram). Each grid cell predicts a fixed number of anchor boxes and confidence scores for those anchor boxes. Each anchor box consists of 5 predictions bx, by, bw, bh and pc (bx,by coordinates of box center; bw, bh lengths of box dimensions, pc confidence) added to the number of classes. The confidence pc here is only for binary classification that those bounding box contains an object or not. With m being the number of input images, the encoded output vector looks the following: (m, nH, nW, anchors, classes), in the case of YOLOv2 that is (m, 13, 13, 5, 85) tensor.

<br><img src="/assets/img/research/grid.jpg" alt="YOLOgrid" style="width:720px">

Source: Modified after <a href="https://unsplash.com/" target="_blank">https://unsplash.com/</a>


### 2. Network Design

The architecture of the YOLOv2 CNN is typical for most CNNs, where the height and width of the image shrinks through un-padded convolutions, but get deeper through increasing filers:

<br><img src="/assets/img/research/The-architecture-of-YOLOv2_W640.jpg" alt="Architecture of YOLOv2" style="width:720px">

Source: <a href="https://www.doi.org/10.3390/s19194263" target="_blank">Seong et al., 2019</a>

The image is resized to 416×416 pixels for training and run through numerous convolutional layers of which many are 1x1 in size to reduce the number of parameters (computational complexity). YOLOv2 removed the 2 fully connected layers and uses anchor boxes to predict bounding boxes.


### 3. Non-Max Suppression

In inference phase, the YOLOv2 algorithm can output multiple bounding boxes for the same object in adjacent tiles and non-max suppression is a technique to resolve it. What non-max suppression do is to keep only the bounding box having maximum confidence score among all boxes that have same classification and have an IoU value (Intersect over Union) >0.5. All boxes that do not meet criteria are eliminated, only the remaining bounding boxes will be displayed.

<br><img src="/assets/img/research/NMS.png" alt="YOLOV2 video" style="width:720px">

Source: Modified after <a href="https://unsplash.com/" target="_blank">https://unsplash.com/</a>

## Outlook
If you wanted to run YOLO, that will not be that easy, since it was originally implemented in C language with a neural network framework called Darknet. Running it in Python and Keras does not require you to do the conversion work yourself. Multiple projects have already done that conversion work for you: for example <a href="https://github.com/allanzelener/YAD2K" target="_blank">Allan Zelener - YAD2K: Yet Another Darknet 2 Keras</a>. YOLO was trained on for some epochs on the pre-trained ImageNet using high-power GPUs. Hence, it is not recommendable to train it yourself. Be advised to download the pre-trained values to make inferences only! The algorithm is continuously optimized, for example with YOLO9000, which vastly inceased the number of classes. Have a read of the links given below on how the different versions of YOLO stack up agains other detection and identification networks.

**Prediction on video feed:**
<br><img src="https://miro.medium.com/max/480/0*CHPbDpMh5oeQlxJt.gif" alt="YOLOV2 video" style="width:720px">

Source: <a href="https://towardsdatascience.com/review-yolov2-yolo9000-you-only-look-once-object-detection-7883d2b02a65" target="_blank">Sik-Ho Tsang 2018</a>

## Further Reading

<a href="https://github.com/ChristianHallerX/Deeplearning.ai/blob/master/4%20Convolutional%20Neural%20Networks/Week%203/Autonomous_driving_application_Car_detection_v3a.ipynb" target="_blank">Jupyter Notebook deeplearning.ai</a>

<a href="https://pjreddie.com/darknet/yolo/" target="_blank">The official YOLO website.</a>

<a href="https://medium.com/@jonathan_hui/real-time-object-detection-with-yolo-yolov2-28b1b93e2088" target="_blank">Jonathan Hui 2018: Real-time Object Detection with YOLO, YOLOv2 and now YOLOv3</a>

<a href="https://towardsdatascience.com/review-yolov2-yolo9000-you-only-look-once-object-detection-7883d2b02a65" target="_blank">Sik-Ho Tsang 2018 Review: YOLOv2 & YOLO9000 — You Only Look Once (Object Detection)</a>


